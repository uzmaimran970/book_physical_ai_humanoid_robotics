---
id: 003
title: Create RAG Chatbot Implementation Plan
stage: plan
date: 2025-12-15
surface: agent
model: claude-sonnet-4-5-20250929
feature: 001-rag-chatbot
branch: 001-rag-chatbot
user: Uzma Imran
command: /sp.plan
labels: ["planning", "architecture", "rag-chatbot", "technical-design", "contracts"]
links:
  spec: /mnt/c/Users/pc/specs/001-rag-chatbot/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - /mnt/c/Users/pc/specs/001-rag-chatbot/plan.md
  - /mnt/c/Users/pc/specs/001-rag-chatbot/research.md
  - /mnt/c/Users/pc/specs/001-rag-chatbot/data-model.md
  - /mnt/c/Users/pc/specs/001-rag-chatbot/quickstart.md
  - /mnt/c/Users/pc/specs/001-rag-chatbot/contracts/api-spec.yaml
  - /mnt/c/Users/pc/specs/001-rag-chatbot/contracts/database-schema.sql
  - /mnt/c/Users/pc/specs/001-rag-chatbot/contracts/qdrant-collection.json
tests:
  - Constitutional compliance validation (all 7 principles checked)
  - Technical context verification (all NEEDS CLARIFICATION resolved)
---

## Prompt

```text
/sp.plan Integrated RAG Chatbot for Published Book

Objective:
Create a detailed execution plan for building the Integrated RAG Chatbot using Claude CLI, SpecifyPlus, Cohere embeddings, Qdrant vector database, FastAPI, and Neon DB.

Plan Requirements:
- Step-by-step backend setup
- Integration of Cohere embeddings for text chunk vectors
- Qdrant collection creation and ingestion of book text
- Claude CLI integration for response generation
- FastAPI endpoints for chat interactions
- Neon DB integration to log queries, context, and answers
- Handling multi-user asynchronous queries
- Ensure latency ‚â§ 2 seconds for each query
- Security and privacy of user data
- Chunking strategy for large books
- Hackathon-ready demo flow

Deliverables:
1. Backend folder structure
   - /backend with main.py, rag_pipeline.py, ingest_docs.py, .env
2. Qdrant collection setup commands
3. Cohere embedding code for documents and queries
4. Claude CLI call integration for RAG responses
5. FastAPI route examples for chat API
6. Neon DB integration code for logging
7. Test plan for multi-user queries
8. Performance optimization plan
9. README.md with setup instructions and hackathon demo steps

Constraints:
- Only Cohere embeddings allowed, no OpenAI API
- Claude CLI mandatory for response generation
- Responses must be strictly based on selected book text
```

## Response snapshot

Created comprehensive implementation plan for RAG chatbot with complete technical architecture, research decisions, data models, API contracts, and hackathon deployment guide.

**Plan File**: `/mnt/c/Users/pc/specs/001-rag-chatbot/plan.md`

### Constitutional Compliance

‚úÖ **All 7 Principles Validated**:

1. **Accuracy & Factual Fidelity** ‚úÖ - Claude prompt enforces "Answer ONLY using retrieved text"; insufficient context ‚Üí "I cannot answer"
2. **Context-Awareness & Traceability** ‚úÖ - Metadata pipeline (chapter, section, page) ensures 100% citation rate
3. **Reliability & Query Logging** ‚úÖ - Complete async logging to Neon DB (queries, chunks, responses, errors)
4. **Performance & Latency Constraints** ‚ö†Ô∏è CONDITIONAL - Estimated 1.25-2.7s; optimizations included (connection pooling, top-3 chunks, Claude Sonnet); load tests required
5. **Privacy & Data Handling** ‚úÖ - Environment variables for secrets, session isolation, no PII logging
6. **Technology Stack Adherence** ‚úÖ - Cohere + Qdrant + Claude + FastAPI + Neon (no OpenAI)
7. **Chunking & Scalability** ‚úÖ - 750-token chunks with 75-token overlap; tiktoken-based; paragraph boundaries

**Overall**: ‚úÖ PASS WITH CONDITIONS (load testing must validate ‚â§2s p90 latency)

### Technical Context (Resolved)

- **Language**: Python 3.11+
- **Dependencies**: FastAPI 0.104+, Cohere SDK 4.x, Qdrant client 1.7+, Anthropic SDK 0.8+, asyncpg 0.29+, Pydantic 2.x, tiktoken 0.5+
- **Storage**: Qdrant Cloud (vectors), Neon Serverless Postgres (logs)
- **Testing**: pytest 7.x, pytest-asyncio, httpx (async client)
- **Performance**: p90 ‚â§2s, 10 concurrent users, optimized pipeline (embed <500ms, search <200ms, LLM <2s)
- **Project Type**: Single backend API (Option 1 from template)

### Phase 0: Research Findings (research.md)

**7 Technology Decisions Documented**:

1. **Cohere Model**: `embed-english-v3.0` (1024 dims) - Accuracy over speed vs light model
2. **Qdrant Config**: Cosine similarity, HNSW (m=16, ef_construct=100) - Balanced speed/accuracy
3. **Claude Prompt**: Structured context + explicit fallback instruction - Reduces hallucination risk
4. **Chunking**: 750 tokens, 75 overlap, paragraph boundaries - Context vs precision trade-off
5. **FastAPI Patterns**: Async + connection pooling + retry logic - Concurrency over simplicity
6. **Neon DB Schema**: UUIDs, JSONB, B-tree indexes - Flexibility over rigid schema
7. **Testing**: Mock units, real integration, load tests - Speed vs confidence

All NEEDS CLARIFICATION items resolved with documented alternatives and rationale.

### Phase 1: Design Artifacts

**1. Data Model (data-model.md)**:
- 6 entities: Book, Chunk, Query, RetrievedChunk, Response, ErrorLog
- Complete ERD with cardinality (1:N, N:M, 1:1, 1:0..1)
- Validation rules: CHECK constraints, UNIQUE constraints, FK cascades
- Sample data for all entities

**2. API Contracts (contracts/api-spec.yaml)**:
- OpenAPI 3.1 schema
- 2 endpoints: `POST /query`, `GET /health`
- Complete request/response schemas
- Error responses: 400 (invalid), 500 (API failure), 503 (unavailable)

**3. Database Schema (contracts/database-schema.sql)**:
- 5 tables: books, queries, responses, retrieved_chunks, error_logs
- 8 indexes (B-tree for time-series, hash for joins)
- 3 views (query_success_rate, avg_latency_by_status, top_errors)
- 1 stored function (log_query_complete for atomic logging)
- Complete DDL with constraints, comments, sample data

**4. Qdrant Collection (contracts/qdrant-collection.json)**:
- Collection config: textbook_chunks, 1024 dims, Cosine, HNSW (m=16)
- Payload schema: 8 fields (chunk_id, book_id, chapter, section, page, index, text, tokens)
- Python creation script included
- Example upsert and search code

**5. Quickstart Guide (quickstart.md)**:
- 6-step setup: venv, dependencies, .env, DB init, Qdrant setup, book ingestion, FastAPI start
- Test commands: health check, sample queries, "cannot answer" test
- Hackathon demo script (5 minutes): intro, live query, concurrent simulation, analytics, Q&A
- Troubleshooting section: Cohere API, Qdrant, Neon DB, latency issues
- Development workflow: testing, formatting, logging

### Project Structure

**Backend Directory Layout** (Option 1: Single Backend):
```
backend/
‚îú‚îÄ‚îÄ src/                      # Application code
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Pydantic + DB models
‚îÇ   ‚îú‚îÄ‚îÄ services/            # Cohere, Qdrant, Claude, Neon wrappers
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Chunking, config, error handling
‚îÇ   ‚îî‚îÄ‚îÄ api/                 # Route definitions
‚îú‚îÄ‚îÄ scripts/                 # One-time setup scripts
‚îÇ   ‚îú‚îÄ‚îÄ ingest_book.py       # Book ingestion
‚îÇ   ‚îú‚îÄ‚îÄ setup_database.py    # DB initialization
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py     # Manual testing
‚îú‚îÄ‚îÄ tests/                   # Unit, integration, contract tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ contract/
‚îú‚îÄ‚îÄ .env.example             # Template
‚îú‚îÄ‚îÄ .env                     # Secrets (gitignored)
‚îú‚îÄ‚îÄ requirements.txt         # Python deps
‚îî‚îÄ‚îÄ README.md                # Setup guide
```

### Performance Optimization Strategy

**Latency Budget** (estimated 1.25-2.7s vs 2s target):
- Cohere embedding: 200-500ms ‚Üí Use `input_type="search_query"` optimization
- Qdrant search: 50-200ms ‚Üí Connection pooling, limit to top-3 chunks
- Claude generation: 1000-2000ms ‚Üí Use Sonnet 4 (faster than Opus), limit context length
- Neon logging: 50-100ms ‚Üí Async (non-blocking, background task)

**Optimizations Implemented**:
- Connection pooling for Qdrant and Neon DB
- Async/await throughout FastAPI endpoints
- Retry logic with exponential backoff (100ms initial delay)
- Structured logging (JSON format for querying)

### Next Steps

**Ready for /sp.tasks**: Run `/sp.tasks` to generate implementation task list organized by:
- Phase 1 (Setup): Project structure, dependencies, .env
- Phase 2 (Foundational): DB schema, Qdrant collection, chunking utils
- Phase 3 (User Story P1 - MVP): Core RAG pipeline (embed, retrieve, generate, cite)
- Phase 4 (User Story P2): Concurrent query handling, load testing
- Phase 5 (User Story P3): Query logging, analytics views
- Phase N (Polish): Documentation, error handling, performance tuning

Tasks will include:
- Test-first directives per constitutional requirements
- Parallelization opportunities ([P] markers)
- Explicit dependencies (T004 depends on T002, T003)
- Checkpoints after each user story for independent testing

## Outcome

- ‚úÖ Impact: Complete technical architecture for RAG chatbot backend with all constitutional requirements satisfied; 7 design artifacts created (plan, research, data model, 3 contracts, quickstart)
- üß™ Tests: Constitutional compliance validated (7/7 principles pass, 1 conditional on load testing)
- üìÅ Files: plan.md (240 lines), research.md (370 lines), data-model.md (410 lines), quickstart.md (520 lines), api-spec.yaml (280 lines), database-schema.sql (420 lines), qdrant-collection.json (95 lines)
- üîÅ Next prompts: `/sp.tasks` to generate implementation task list with test-first TDD workflow
- üß† Reflection: Plan balances pragmatism (hackathon constraints) with constitutional rigor (accuracy, traceability, privacy). Latency budget is tight (1.25-2.7s vs 2s target) but optimizations are concrete and testable. All NEEDS CLARIFICATION items resolved with documented alternatives. Ready for implementation.

## Evaluation notes (flywheel)

- Failure modes observed: None - planning completed without blockers; all technical unknowns resolved through research
- Graders run and results (PASS/FAIL): Constitutional Check - 7/7 principles validated (PASS with conditions on load testing)
- Prompt variant (if applicable): Standard /sp.plan workflow with comprehensive user requirements
- Next experiment (smallest change to try): During `/sp.tasks`, ensure T001-T010 (Setup + Foundational phases) are explicitly marked as blockers for User Story P1 tasks to enforce dependency ordering and prevent premature RAG pipeline implementation
